{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Z9seIY-dB2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSemqh67_fCG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "%matplotlib inline\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHiwu8fP_iTf"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/US_Accidents_Dec20_updated.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne-aIIGW_kJ2"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-gBvUHI_o3-"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbUOXipbAF05"
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AUKyWpFAH8c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNM_DSUiANWb"
      },
      "source": [
        "df.Severity.value_counts(normalize=True).sort_index().plot.bar()\n",
        "plt.grid()\n",
        "plt.title('Severity')\n",
        "plt.xlabel('Severity')\n",
        "plt.ylabel('Fraction');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKWLtK-lAPzM"
      },
      "source": [
        "bool_cols = [col for col in df.columns if df[col].dtype ==np.dtype('bool')]\n",
        "booldf = df[bool_cols]\n",
        "not_one_hot = booldf[booldf.sum(axis=1) > 1]\n",
        "print('There are {} non one hot metadata rows, which are {:.1f}% of the data'.format(len(not_one_hot),100*len(not_one_hot)/len(df)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQIMWygtASJO"
      },
      "source": [
        "bools = booldf.sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHono13AZOO"
      },
      "source": [
        "bools.plot.pie(figsize=(13,13))\n",
        "plt.ylabel('')\n",
        "plt.title('Proximity to Traffic Object');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oES05Q8QAci6"
      },
      "source": [
        "st = pd.to_datetime(df.Start_Time, format='%Y-%m-%d %H:%M:%S')\n",
        "end = pd.to_datetime(df.End_Time, format='%Y-%m-%d %H:%M:%S')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ugpqcFgAhVC"
      },
      "source": [
        "diff = (end-st)\n",
        "top20 = diff.astype('timedelta64[m]').value_counts().nlargest(20)\n",
        "print('top 20 accident durations correspond to {:.1f}% of the data'.format(top20.sum()*100/len(diff)))\n",
        "(top20/top20.sum()).plot.bar(figsize=(14,14))\n",
        "plt.title('Accident Duration [Minutes]')\n",
        "plt.xlabel('Duration [minutes]')\n",
        "plt.ylabel('Fraction');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoi3t2ZRAnf7"
      },
      "source": [
        "df['time'] = pd.to_datetime(df.Start_Time, format='%Y-%m-%d %H:%M:%S')\n",
        "df = df.set_index('time')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGjrQfkWAqmf"
      },
      "source": [
        "freq_text = {'D':'Daily','W':'Weekly','Y':'Yearly'}\n",
        "plt.subplots(1,3,figsize=(21,7))\n",
        "for i, (fr,text) in enumerate(freq_text.items(),1):\n",
        "    plt.subplot(1,3,i)\n",
        "    sample = df.ID['2016':].resample(fr).count()\n",
        "    sample.plot(style='.')\n",
        "    plt.title('Accidents, {} count'.format(text))\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Accident Count');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2dWldFUAty7"
      },
      "source": [
        "years = ['2016','2017','2018']\n",
        "fig, _ = plt.subplots(1,3,figsize=(21,7), sharex='all', sharey='all')\n",
        "\n",
        "fig.suptitle('Accidents by month for Different Years')\n",
        "plt.xlabel('month')\n",
        "plt.ylabel('Accidents')\n",
        "for i, year in enumerate(years,1):\n",
        "    plt.subplot(1,3,i)\n",
        "    sample = df.loc[year].ID.resample('M').count()\n",
        "    sample.plot()\n",
        "    plt.ylim(0,100000)\n",
        "    plt.title('Accidents, {} count'.format(text))\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Accident Count');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DwtBoX_A_Vl"
      },
      "source": [
        "df['Weekday'] = df.index.day_name()\n",
        "weekday = df.groupby('Weekday').ID.count()\n",
        "weekday = weekday/weekday.sum()\n",
        "dayOfWeek=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
        "weekday[dayOfWeek].plot.bar()\n",
        "plt.title('Accidents by Weekday')\n",
        "plt.xlabel('Weekday')\n",
        "plt.ylabel('Accidents');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzu0G696BDij"
      },
      "source": [
        "years = ['2016','2017','2018']\n",
        "fig, _ = plt.subplots(1,3,figsize=(21,7), sharex='all', sharey='all')\n",
        "\n",
        "fig.suptitle('Accidents by Weekday for Different Years')\n",
        "plt.xlabel('Weekday')\n",
        "plt.ylabel('Accidents')\n",
        "for i, year in enumerate(years,1):\n",
        "    weekday = df.loc[year].groupby('Weekday').ID.count()\n",
        "    weekday = weekday/weekday.sum()\n",
        "    dayOfWeek=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
        "    plt.subplot(1,3,i)\n",
        "    plt.title(year)\n",
        "    weekday[dayOfWeek].plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA5-QDrQBGyi"
      },
      "source": [
        "def plotCorrelationMatrix(df, graphWidth):\n",
        "    df = df.dropna('columns') # drop columns with NaN\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    if df.shape[1] < 2:\n",
        "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
        "        return\n",
        "    corr = df.corr()\n",
        "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
        "    corrMat = plt.matshow(corr, fignum = 1)\n",
        "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.colorbar(corrMat)\n",
        "    plt.title('Correlation Matrix, fontsize=15')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yibwkl3NBKG8"
      },
      "source": [
        "plotCorrelationMatrix(df, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT_n5dBrBPuX"
      },
      "source": [
        "df.groupby('State') \\\n",
        "        .size() \\\n",
        "        .iloc[:10] \\\n",
        "        .sort_values(ascending=False) \\\n",
        "        .plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qqRHFYzBQnj"
      },
      "source": [
        "df1 = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_sfcftPBTBh"
      },
      "source": [
        "df1.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwLl85yrBTFK"
      },
      "source": [
        "df1.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4PAkwUGBTLs"
      },
      "source": [
        "df1 = df1.drop(['Distance(mi)', 'Country', 'Description', 'City', 'County', 'Street', 'Side', 'Zipcode', 'State', 'Airport_Code', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsvYcd7yBTO6"
      },
      "source": [
        "cols = [\"End_Lat\", \"End_Lng\", \"Number\"]\n",
        "df1 = df1.drop(cols, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNg5s0tfBTQ8"
      },
      "source": [
        "df1.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LgReBLVBn0g"
      },
      "source": [
        "pmean = df1['Pressure(in)'].mean()\n",
        "tmean = df1['Temperature(F)'].mean()\n",
        "wcmean = df1['Wind_Chill(F)'].mean()\n",
        "hmean = df1['Humidity(%)'].mean()\n",
        "wsmean = df1['Wind_Speed(mph)'].mean()\n",
        "prmean = df1['Precipitation(in)'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0loCnSqtBrfN"
      },
      "source": [
        "df1['Pressure(in)']=df1['Pressure(in)'].fillna(pmean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esfHDOUjBrie"
      },
      "source": [
        "df1['Temperature(F)'] = df1['Temperature(F)'].fillna(tmean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEzUspryBrlE"
      },
      "source": [
        "df1['Wind_Chill(F)'] = df1['Wind_Chill(F)'].fillna(wcmean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tm98_uRBrnk"
      },
      "source": [
        "df1['Humidity(%)'] = df1['Humidity(%)'].fillna(hmean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9brk_-pSBrps"
      },
      "source": [
        "df1['Wind_Speed(mph)'] = df1['Wind_Speed(mph)'].fillna(wsmean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI847GdQBru9"
      },
      "source": [
        "df1['Precipitation(in)']=df1['Precipitation(in)'].fillna(prmean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X44kQznPBryU"
      },
      "source": [
        "df1.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjiwcxaBBr0Z"
      },
      "source": [
        "df1.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3PPjFobC0YF"
      },
      "source": [
        "visMode = df1[\"Visibility(mi)\"].mode()\n",
        "#df1[\"Visibility(mi)\"]=df1[\"Visibility(mi)\"].fillna(visMode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dES3JHCC2mp"
      },
      "source": [
        "#df1[\"Visibility(mi)\"]=df1[\"Visibility(mi)\"].fillna(visMode)\n",
        "df1['Visibility(mi)'] = df1['Visibility(mi)'].fillna(df1['Visibility(mi)'].mode()[0])\n",
        "df1['Wind_Direction'] = df1['Wind_Direction'].fillna(df1['Wind_Direction'].mode()[0])\n",
        "df1['Weather_Condition'] = df1['Weather_Condition'].fillna(df1['Weather_Condition'].mode()[0])\n",
        "#df1['Sunrise_Sunset'] = df1['Sunrise_Sunset'].fillna(df1['Sunrise_Sunset'].mode()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_gACuhWC4yw"
      },
      "source": [
        "df1.drop(['Timezone','Weather_Timestamp', 'Start_Time', 'End_Time', 'ID'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlPkqSxuC8em"
      },
      "source": [
        "df1.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZuuuo2rC-uy"
      },
      "source": [
        "df1.dropna(axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdAtVfphDMMJ"
      },
      "source": [
        "df1.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iSOHgSPDMO3"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df1['Amenity'] = label_encoder.fit_transform(df1['Amenity'])\n",
        "df1['Bump'] = label_encoder.fit_transform(df1['Bump'])\n",
        "df1['Crossing'] = label_encoder.fit_transform(df1['Crossing'])\n",
        "df1['Give_Way'] = label_encoder.fit_transform(df1['Give_Way'])\n",
        "df1['Junction'] = label_encoder.fit_transform(df1['Junction'])\n",
        "df1['No_Exit'] = label_encoder.fit_transform(df1['No_Exit'])\n",
        "df1['Railway'] = label_encoder.fit_transform(df1['Railway'])\n",
        "df1['Roundabout'] = label_encoder.fit_transform(df1['Roundabout'])\n",
        "df1['Station'] = label_encoder.fit_transform(df1['Station'])\n",
        "df1['Stop'] = label_encoder.fit_transform(df1['Stop'])\n",
        "df1['Traffic_Calming'] = label_encoder.fit_transform(df1['Traffic_Calming'])\n",
        "df1['Traffic_Signal'] = label_encoder.fit_transform(df1['Traffic_Signal'])\n",
        "df1['Turning_Loop'] = label_encoder.fit_transform(df1['Turning_Loop'])\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3rDAYI_DMTl"
      },
      "source": [
        "df1['Sunrise_Sunset'] = label_encoder.fit_transform(df1['Sunrise_Sunset'])\n",
        "df1['Weather_Condition'] = label_encoder.fit_transform(df1['Weather_Condition'])\n",
        "df1['Wind_Direction'] = label_encoder.fit_transform(df1['Wind_Direction'])\n",
        "df1['Weekday'] = label_encoder.fit_transform(df1['Weekday'])\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrZKUXRfDMVq"
      },
      "source": [
        "df1.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO8fAI8PDMXy"
      },
      "source": [
        "Y = df1['Severity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NHEr9VjDb3W"
      },
      "source": [
        "X = df1.drop(['Severity'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYTqaMTNDb5g"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19tZVLnHDb8D"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Make an instance of the Model\n",
        "pca = PCA(.95)\n",
        "pca.fit(X)\n",
        "train_img = pca.transform(X)\n",
        "train = pd.DataFrame(train_img)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yuDbbkyDb-Y"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8t_zhAzDkgF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-IzbOu5DkiE"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "# Fit on training set only.\n",
        "scaler.fit(X_train)\n",
        "# Apply transform to both the training set and the test set.\n",
        "transform = scaler.transform(X_train)\n",
        "#test_img = scaler.transform(test_img)\n",
        "scalar_train = pd.DataFrame(transform)\n",
        "scalar_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqaLsKa7N1hG"
      },
      "source": [
        "scalert = StandardScaler()\n",
        "# Fit on training set only.\n",
        "scalert.fit(X_test)\n",
        "# Apply transform to both the training set and the test set.\n",
        "transformt = scalert.transform(X_test)\n",
        "#test_img = scaler.transform(test_img)\n",
        "scalar_test = pd.DataFrame(transformt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2EU3kS3DkkG"
      },
      "source": [
        "y_train.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PmLzTFCDvp_"
      },
      "source": [
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YEfZ4_xHhGw"
      },
      "source": [
        "pip install hummingbird-ml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvHZny3THhyH"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from hummingbird.ml import convert, load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq5zYsx4DvvC"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# import neural_structured_learning as nsl\n",
        "\n",
        "# # Prepare data.\n",
        "# # (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# # x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# # Create a base model -- sequential, functional, or subclass.\n",
        "# model = tf.keras.Sequential([\n",
        "#     # tf.keras.Input((1,1), name='feature'),\n",
        "#     #tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(128, input_shape=(26,), activation=tf.nn.relu),\n",
        "#     tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "# ]\n",
        "# )\n",
        "\n",
        "# # Wrap the model with adversarial regularization.\n",
        "# adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)\n",
        "# adv_model = nsl.keras.AdversarialRegularization(model, adv_config=adv_config)\n",
        "\n",
        "# # # Compile, train, and evaluate.\n",
        "# adv_model.compile(optimizer='adam',\n",
        "#                   loss='sparse_categorical_crossentropy',\n",
        "#                   metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# adv_model.fit({'feature': X_train, 'label': y_train}, batch_size=32, epochs=5)\n",
        "# adv_model.evaluate({'feature': X_test, 'label': y_test})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fhX0FsiDvxN"
      },
      "source": [
        "# _, accuracy = model.evaluate(X_test, y_test)\n",
        "# print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6_GYPMsDvzI"
      },
      "source": [
        "num_classes = 2\n",
        "# X = np.random.rand(100000, 28)\n",
        "# y = np.random.randint(num_classes, size=100000)\n",
        "\n",
        "# Create and train a model (scikit-learn RandomForestClassifier in this case)\n",
        "skl_model = RandomForestClassifier(n_estimators=10, max_depth=10)\n",
        "skl_model.fit(scalar_train,y_train)\n",
        "\n",
        "# Use Hummingbird to convert the model to PyTorch\n",
        "model = convert(skl_model, 'pytorch')\n",
        "\n",
        "# Run predictions on CPU\n",
        "model.predict(scalar_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf-5t1FHDv1T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}